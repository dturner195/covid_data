{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# COVID and demographic info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#Combine weekly and monthly unemployment data as granular as possible\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "path = Path(r'/Users/_DMT/jupyter/covid')\n",
    "import CovidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "%%writefile /Users/_DMT/jupyter/covid/CovidData/__init__.py\n",
    "\n",
    "from CovidClass.CovidData import CovidData\n",
    "from CovidClass.GeoCovidData import GeoCovidData\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Covid data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/_DMT/jupyter/covid/CovidClass/CovidData.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /Users/_DMT/jupyter/covid/CovidClass/CovidData.py\n",
    "\n",
    "# Import dependencies\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "path = Path(r'/Users/_DMT/jupyter/covid')\n",
    "\n",
    "class CovidData:\n",
    "    '''\n",
    "    Class to pull, merge, and display latest US COVID-19 cases and death data, combined\n",
    "    with unemployment numbers and county demographics\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #get time for reference\n",
    "        self.now = datetime.today()\n",
    "        \n",
    "        #Get dates of latest data updates\n",
    "        dates = pd.read_csv(path/'var_dates.csv', index_col=[0])\n",
    "\n",
    "        # Gets the polygons for US counties, see Geo.ipynb for source\n",
    "        self.df_fips = pd.read_csv(path/'fips_and_counties.csv', index_col=[0], dtype='str')\n",
    "    \n",
    "        \n",
    "        self.df_fips.geometry = self.df_fips.geometry.apply(wkt.loads)             \n",
    "            \n",
    "        # Date_parse not working so...\n",
    "        for col in dates.columns:\n",
    "            dates[col] = pd.to_datetime(dates[col])\n",
    "        \n",
    "        \n",
    "        self.county_replace = [' County', ' Municipio', ' Parish', ' City and Borough', 'City and Borough of ',' Borough/city',  ' Borough/municipality',\n",
    "                             ' Municipality', 'Municipality of ', ' Borough', ' Census Area', ' (including other portions of Kansas City)']\n",
    "        \n",
    "        \n",
    "        self.dates = dates\n",
    "        #state flip\n",
    "        #FYI in the county level data, DC is ia \n",
    "\n",
    "        self.us_state_abbrev = {\n",
    "            'Alabama': 'AL',\n",
    "            'Alaska': 'AK',\n",
    "            'American Samoa': 'AS',\n",
    "            'Arizona': 'AZ',\n",
    "            'Arkansas': 'AR',\n",
    "            'California': 'CA',\n",
    "            'Colorado': 'CO',\n",
    "            'Connecticut': 'CT',\n",
    "            'Delaware': 'DE',\n",
    "            'District of Columbia': 'DC',\n",
    "            'Florida': 'FL',\n",
    "            'Georgia': 'GA',\n",
    "            'Guam': 'GU',\n",
    "            'Hawaii': 'HI',\n",
    "            'Idaho': 'ID',\n",
    "            'Illinois': 'IL',\n",
    "            'Indiana': 'IN',\n",
    "            'Iowa': 'IA',\n",
    "            'Kansas': 'KS',\n",
    "            'Kentucky': 'KY',\n",
    "            'Louisiana': 'LA',\n",
    "            'Maine': 'ME',\n",
    "            'Maryland': 'MD',\n",
    "            'Massachusetts': 'MA',\n",
    "            'Michigan': 'MI',\n",
    "            'Minnesota': 'MN',\n",
    "            'Mississippi': 'MS',\n",
    "            'Missouri': 'MO',\n",
    "            'Montana': 'MT',\n",
    "            'Nebraska': 'NE',\n",
    "            'Nevada': 'NV',\n",
    "            'New Hampshire': 'NH',\n",
    "            'New Jersey': 'NJ',\n",
    "            'New Mexico': 'NM',\n",
    "            'New York': 'NY',\n",
    "            'North Carolina': 'NC',\n",
    "            'North Dakota': 'ND',\n",
    "            'Northern Mariana Islands':'MP',\n",
    "            'Ohio': 'OH',\n",
    "            'Oklahoma': 'OK',\n",
    "            'Oregon': 'OR',\n",
    "            'Pennsylvania': 'PA',\n",
    "            'Puerto Rico': 'PR',\n",
    "            'Rhode Island': 'RI',\n",
    "            'South Carolina': 'SC',\n",
    "            'South Dakota': 'SD',\n",
    "            'Tennessee': 'TN',\n",
    "            'Texas': 'TX',\n",
    "            'Utah': 'UT',\n",
    "            'Vermont': 'VT',\n",
    "            'Virgin Islands': 'VI',\n",
    "            'Virginia': 'VA',\n",
    "            'Washington': 'WA',\n",
    "            'West Virginia': 'WV',\n",
    "            'Wisconsin': 'WI',\n",
    "            'Wyoming': 'WY'\n",
    "        }\n",
    "\n",
    "        # Flip the other way\n",
    "        self.us_state_flip = {v:k for k,v in self.us_state_abbrev.items()}\n",
    "\n",
    "    # Use USAfacts data\n",
    "    def get_usafacts_covid(self):\n",
    "        '''\n",
    "        Gets latest covid cases and deaths from USAfacts\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame of cases, deaths by US county with population\n",
    "        '''\n",
    "        \n",
    "        cases_url = 'https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv'\n",
    "        deaths_url = 'https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv'\n",
    "        population_url = 'https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_county_population_usafacts.csv'\n",
    "\n",
    "        cases = pd.read_csv(cases_url, dtype='str').melt(id_vars=['countyFIPS', 'County Name', 'State', 'stateFIPS'], \n",
    "                           value_name='Cases', var_name='Date')\n",
    "\n",
    "        cases.loc[cases['County Name'] =='Statewide Unallocated', 'countyFIPS'] = cases.loc[cases['County Name'] == \n",
    "                                                                                   'Statewide Unallocated', 'stateFIPS'] + '000'\n",
    "\n",
    "\n",
    "        deaths = pd.read_csv(deaths_url, dtype='str').melt(id_vars=['countyFIPS', 'County Name', 'State', 'stateFIPS'], \n",
    "                           value_name='Deaths', var_name='Date')\n",
    "\n",
    "        deaths.loc[deaths['County Name'] =='Statewide Unallocated', 'countyFIPS'] = deaths.loc[deaths['County Name'] == \n",
    "                                                                                   'Statewide Unallocated', 'stateFIPS'] + '000'\n",
    "\n",
    "        df = pd.merge(cases, deaths[['countyFIPS', 'State', 'Date', 'Deaths']], on=['countyFIPS', 'State','Date'])\n",
    "\n",
    "        pop = pd.read_csv(population_url, dtype='str')\n",
    "        # Merge in populations, dropping unallocated, which are 0 and cause join issues\n",
    "        df = pd.merge(df, pop[['countyFIPS', 'population']].drop(pop[pop.countyFIPS == '0'].index), on=['countyFIPS'], how='left')\n",
    "\n",
    "        df['countyFIPS'] = df['countyFIPS'].str.zfill(5)\n",
    "        \n",
    "        \n",
    "        df['County Name'] = df['County Name'].str.replace('|'.join(self.county_replace), '')\n",
    "        \n",
    "        df['State'] = df['State'].apply(lambda x:  self.us_state_flip.get(x, np.nan))\n",
    "\n",
    "        df.drop('stateFIPS', axis=1, inplace=True)\n",
    "        df.columns = ['fips', 'County', 'State', 'Date', 'Cases', 'Deaths', 'Population']\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        bol = (~df['Deaths'].str.isnumeric() | ~df['Cases'].str.isnumeric() | \n",
    "               ~df.loc[~df['Population'].isna(),'Population'].str.isnumeric())\n",
    "\n",
    "        try:\n",
    "            df['Cases'] = df['Cases'].astype('int')\n",
    "            df['Deaths'] = df['Deaths'].astype('int')\n",
    "            df['Population'] = df['Population'].astype('float64').astype('Int64')\n",
    "\n",
    "        except:\n",
    "            # Display data rows with potential error\n",
    "            # Note: negative cases/deaths will be displayed, but can be set to int\n",
    "            \n",
    "            print(f'ERROR: Covid data issue on\\n{df[bol]}')\n",
    "            df = pd.read_csv(path/'covid_states.csv', index_col=[0], dtype='str')\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df['Cases'] = df['Cases'].astype('int')\n",
    "            df['Deaths'] = df['Deaths'].astype('int')\n",
    "            df['Population'] = df['Population'].astype('float64').astype('Int64')\n",
    "            print('Previous data loaded')\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    #Gets the county ratio of unemployment claims\n",
    "    def county_ratio(self, dfc, dfw):\n",
    "        '''\n",
    "        Pulls the weekly unemployment insurance claims and estimates the share per county\n",
    "        \n",
    "        Args:\n",
    "            \n",
    "            dfc (DataFrame): Covid data\n",
    "            dfw (DataFrame): Weekly unmployment claims by state\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        series = dfc['State'].value_counts()\n",
    "\n",
    "        try:\n",
    "            dfw.set_index('Date', inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        df_int = pd.DataFrame(columns = dfw.columns)\n",
    "        dfc['Share_lf'] = np.nan\n",
    "\n",
    "        #use first date to avoid duplication\n",
    "        d = dfc['Date'][0]\n",
    "\n",
    "        for s in series.index:\n",
    "            #get the total labor force as share of population\n",
    "            total = dfc.loc[(dfc['State'] == s) & (dfc['Date'] == d), 'Population'].sum()\n",
    "            dfc.loc[dfc['State'] == s,'Share_lf'] = dfc.loc[dfc['State'] == s,'Population'] / total\n",
    "\n",
    "\n",
    "            #get the share of the weekly insurance claims interpolated\n",
    "            #divide by 4 so the total weekly claims add up (add 6 new days plus 2 originial days over 2 original days = 4 )\n",
    "            temp = dfw[dfw['State'] == s].resample('D').mean().interpolate(method='linear') * (1/4)\n",
    "            temp['State'] = s\n",
    "            df_int = df_int.append(temp.reset_index(), sort=True)\n",
    "\n",
    "        if np.issubdtype(df_int['Date'].dtype, np.datetime64):\n",
    "            df_int['Date'] = df_int.Date.dt.date.astype(str)\n",
    "        if np.issubdtype(dfc['Date'].dtype, np.datetime64):\n",
    "            dfc['Date'] = dfc.Date.dt.date.astype(str)\n",
    "        dfw.reset_index(inplace=True)\n",
    "        if np.issubdtype(dfw['Date'].dtype, np.datetime64):\n",
    "            dfw['Date'] = dfw.Date.dt.date.astype(str)\n",
    "\n",
    "\n",
    "        df = pd.merge(dfc, df_int, how='left', on=['Date', 'State'])\n",
    "        df['Est_claims'] = df['Share_lf'] * df['Initial_claims']\n",
    "\n",
    "        # Get original weekly data, with share by county\n",
    "        df['UI claims'] = df['Share_lf'] * pd.merge(df[['Date', 'State']], dfw, how='left', on=['Date', 'State']).drop(['Date', 'State'], axis=1)['Initial_claims']\n",
    "\n",
    "        return df.drop(['Share_lf', 'Initial_claims'], axis=1)\n",
    "    \n",
    "    \n",
    "    # Get the latest update on the BLS data\n",
    "\n",
    "    def get_bls_time(self):\n",
    "        '''\n",
    "        Gets the latest unemlpoyment dates from BLS data\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            datetime object (month year of latest unemployment)\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        df = pd.read_csv(r'https://www.bls.gov/web/metro/laucntycur14.txt', \n",
    "                                      nrows=1, header=None, engine='python'\n",
    "                                     ).iloc[0,2].replace('(p)','').split('-')[1]\n",
    "        self.bls_latest = datetime.strptime(df, '%B %Y')\n",
    "        \n",
    "        return self.bls_latest\n",
    "    \n",
    "    \n",
    "    #Pull county unemployment data\n",
    "    def get_unemp_data(self, start_date = '2020-01'):\n",
    "        '''\n",
    "        Pulls latest conty unemployment data from BLS website\n",
    "        \n",
    "        Arg:\n",
    "        \n",
    "            start_date (string): default = '2020-01', the data from which to pull the unemployment data\n",
    "            \n",
    "        Retruns:\n",
    "        \n",
    "            DataFrame of unemployment by county\n",
    "        \n",
    "        '''\n",
    "\n",
    "        df = pd.read_csv(r'https://www.bls.gov/web/metro/laucntycur14.txt', sep='\\|', \n",
    "                         header=None, skiprows=6, engine='python', dtype='str', skipfooter=6)\n",
    "        df[3] = df[3].str.strip()\n",
    "        df[4] = pd.to_datetime(df[4].str.replace('\\(p\\)','').str.strip(), format='%b-%y')\n",
    "\n",
    "        for i in range(5,9):\n",
    "            df[i] = pd.to_numeric(df[i].str.replace(',',''), errors='coerce')\n",
    "\n",
    "        df.columns = ['area_code', 'state_fips', 'county_fips', 'Location', 'Date', 'Labor force', \n",
    "                      'Employed', 'Unemployed', 'Unemployment rate']\n",
    "        df['fips'] = df['state_fips'].str.strip() + df['county_fips'].str.strip()\n",
    "        df.drop(['area_code', 'state_fips', 'county_fips'], axis=1, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df['County'] = df['Location'].apply(lambda x: x.split(', ')[0])\n",
    "        # Make DC county and state\n",
    "        df.loc[df['Location'] == 'District of Columbia', 'Location'] = 'District of Columbia, District of Columbia'\n",
    "        df['State'] = df['Location'].apply(lambda x:  self.us_state_flip.get(x.split(', ')[1], np.nan))\n",
    "\n",
    "        df['County'] = df['County'].str.replace('|'.join(self.county_replace), '')\n",
    "\n",
    "        self.unemp_data = df[df['Date'] >= start_date]\n",
    "        \n",
    "        return self.unemp_data\n",
    "\n",
    "    \n",
    "    \n",
    "    #Pull weekly claims data\n",
    "    def get_weekly_claims_data(self):\n",
    "        '''\n",
    "        Gets latest weekly unemployment claims and scrubs\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        df_weekly = pd.read_csv('https://oui.doleta.gov/unemploy/csv/ar539.csv', low_memory=False)\n",
    "        weekly_time_stamp = datetime.strptime(df_weekly.loc[0, 'priorwk_pub'], '%m/%d/%Y')\n",
    "        df_weekly.drop(['c1', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c22', 'c23', 'curdate', 'priorwk_pub', 'priorwk'], axis=1, inplace=True)\n",
    "        df_weekly.columns = ['State', 'Rpt_date','Week_end', 'Initial_claims', 'Rate_insured_unemp', 'Two_year_ave', 'Current_over_2year']\n",
    "\n",
    "        df_weekly['State'] = df_weekly['State'].apply(lambda x: self.us_state_flip[x])\n",
    "        df_weekly['Week_end'] = pd.to_datetime(df_weekly['Week_end'])\n",
    "        df_weekly['Rpt_date'] = pd.to_datetime(df_weekly['Rpt_date'])\n",
    "\n",
    "        df_weekly_thin = df_weekly[['State', 'Week_end', 'Initial_claims', 'Rate_insured_unemp']][df_weekly['Week_end'] > '2020-01-01']\n",
    "        df_weekly_thin.columns = ['Date' if x == 'Week_end' else x for x in df_weekly_thin.columns]\n",
    "        df_weekly_thin['Date'] = pd.to_datetime(df_weekly_thin['Date'])\n",
    "        \n",
    "        self.dates.Weekly[0] = weekly_time_stamp\n",
    "        \n",
    "        \n",
    "        return df_weekly_thin\n",
    "    \n",
    "    \n",
    "    # Split cenus data into per capita income\n",
    "    def get_percap_census_data(self):\n",
    "        '''\n",
    "        Pulls the per capita income by county from census data (stored locally)\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #Currently pulling directly and saving to hardrive\n",
    "        df_income = pd.read_csv(path/'per_capita_income_by_county.csv', encoding='latin-1', skipfooter=3, engine='python')\n",
    "\n",
    "        #gets only the data with counties\n",
    "        bol = (df_income['GeoName'].str.contains(',')) & ~(df_income['GeoName'].str.contains('\\+'))\n",
    "        temp = df_income.loc[bol,'GeoName'].str.split(', ')\n",
    "        df_income.loc[bol, 'County'] = temp.apply(lambda x: x[0])\n",
    "        df_income.loc[bol, 'State'] = temp.apply(lambda x: x[1])\n",
    "\n",
    "        df_income.loc[bol, 'State'] = df_income.loc[bol,'State'].apply(lambda x: self.us_state_flip[x.strip('*')])\n",
    "        df_income.columns = ['fips' if c == 'GeoFIPS' else c for c in df_income.columns]\n",
    "        df_income['fips'] = df_income['fips'].str.replace('\"', '').str.strip()\n",
    "\n",
    "        self.df_income = df_income[df_income['Unit'] == 'Dollars'].dropna()[['fips', '2018', 'County', 'State']]\n",
    "        \n",
    "        self.df_income.columns = ['fips', 'Per capita income', 'County', 'State']\n",
    "        self.df_income['County'] = self.df_income['County'].str.replace('|'.join(self.county_replace), '')\n",
    "        \n",
    "        return self.df_income\n",
    "    \n",
    "    def get_age(self):\n",
    "        '''\n",
    "        Pulls in age distribution by county form US Census\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame\n",
    "        '''\n",
    "        self.df_age = pd.read_csv(path/'age_dist.csv', index_col=[0])\n",
    "        self.df_age['fips'] = self.df_age['fips'].apply(lambda x: str(x).zfill(5))\n",
    "    \n",
    "        return self.df_age\n",
    "    \n",
    "    # Data from USA facts, updated at midnight PST\n",
    "    def get_covid(self):\n",
    "        '''\n",
    "        Checks if covid data is new and pulls if needed\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame\n",
    "        '''\n",
    "        \n",
    "        # Dates to use for recent pull or not\n",
    "        \n",
    "\n",
    "        if (self.now - self.dates.Covid[0]).days >= 0:\n",
    "\n",
    "            self.df_covid = self.get_usafacts_covid()\n",
    "            self.df_covid.to_csv(path/'covid_states.csv')\n",
    "            self.dates.Covid[0] = self.now\n",
    "            \n",
    "        else:\n",
    "            self.df_covid = pd.read_csv(path/'covid_states.csv', index_col=[0])\n",
    "            self.df_covid['Date'] = pd.to_datetime(self.df_covid['Date'])\n",
    "            \n",
    "            \n",
    "        print('Last cases date:', self.df_covid['Date'].max().strftime('%Y-%m-%d'))\n",
    "    \n",
    "        return self.df_covid\n",
    "    \n",
    "    \n",
    "            #Monthly available data, only pull once per month\n",
    "        \n",
    "    def get_bls(self):\n",
    "        '''\n",
    "        Pulls unemployment data by county if new\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame\n",
    "        '''\n",
    "\n",
    "\n",
    "        self.get_bls_time()\n",
    "\n",
    "        #pull if data has freshened\n",
    "        if ((self.bls_latest - self.dates.BLS[0]).days > 0):\n",
    "\n",
    "            self.df_county_data = self.get_unemp_data()\n",
    "            #save to csv\n",
    "            self.df_county_data.to_csv(path/'county_unemployment.csv')\n",
    "            self.dates.BLS[0] = self.bls_latest\n",
    "\n",
    "        else:\n",
    "            self.df_county_data = pd.read_csv(path/'county_unemployment.csv', index_col=[0], dtype='str')\n",
    "            self.df_county_data['Date'] = pd.to_datetime(self.df_county_data['Date'])\n",
    "            col_to_numeric = ['Labor force', 'Employed', 'Unemployed', 'Unemployment rate']\n",
    "            for i in col_to_numeric:\n",
    "                self.df_county_data[i] = pd.to_numeric(self.df_county_data[i], errors='coerce')\n",
    "\n",
    "        print('BLS data current as of:', datetime.strftime(self.bls_latest, '%b-%Y'))\n",
    "\n",
    "        return self.df_county_data\n",
    "    \n",
    "    \n",
    "    def get_weekly(self):\n",
    "        '''\n",
    "        Gets weekly unemployment claims if the data are new\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        if (self.now - self.dates.Weekly[0]).days >= 7:\n",
    "            \n",
    "            try:\n",
    "                self.df_weekly= self.get_weekly_claims_data()\n",
    "                self.df_weekly.to_csv(path/'claims_thin.csv')\n",
    "\n",
    "            except:\n",
    "                self.df_weekly = pd.read_csv(path/'claims_thin.csv', index_col=[0])\n",
    "            \n",
    "        else:\n",
    "            #get saved weekly unemployment data\n",
    "            self.df_weekly = pd.read_csv(path/'claims_thin.csv', index_col=[0])\n",
    "            self.df_weekly['Date'] = pd.to_datetime(self.df_weekly['Date'])\n",
    "            self.df_weekly.set_index('Date', inplace=True)\n",
    "\n",
    "        print('Latest unemployment claims date:', self.dates.Weekly[0].strftime('%Y-%m-%d'))\n",
    "    \n",
    "        return self.df_weekly\n",
    "    \n",
    "    #Descart labs mobility info\n",
    "    def get_descartes(self):\n",
    "        '''\n",
    "        Pulls Descartes labs mobility info\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            DataFrame\n",
    "        '''\n",
    "        dc_url = r'https://raw.githubusercontent.com/descarteslabs/DL-COVID-19/master/DL-us-mobility-daterow.csv'\n",
    "\n",
    "        df = pd.read_csv(dc_url, dtype='str')\n",
    "        df.drop(['country_code', 'admin_level'], axis=1, inplace=True)\n",
    "        df['samples'] = df['samples'].astype('int64')\n",
    "        df['m50'] = df['m50'].astype('float64')\n",
    "        df['m50_index'] = df['m50_index'].astype('float64')\n",
    "        df.columns = ['Date', 'State', 'County', 'fips', 'Samples', 'Raw', 'Mobility index']\n",
    "\n",
    "        df['State only'] = (df['County'].isna()) & ~(df['State'].isna())\n",
    "        df.loc[:, 'County'] = df['County'].str.replace('|'.join(self.county_replace), '')\n",
    "        print('Latest mobility:', df.Date.max())\n",
    "        self.df_descartes = df\n",
    "        self.df_descartes['Date'] = pd.to_datetime(self.df_descartes['Date'])\n",
    "        self.df_descartes.to_csv(path/'descartes_mobility.csv')\n",
    "        \n",
    "        return self.df_descartes\n",
    "    \n",
    " \n",
    "    \n",
    "    def merge_data(self):    \n",
    "        '''\n",
    "        Merges the dataframes collected\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            DataFrame\n",
    "        '''\n",
    "        self.df_covid['Month'] = self.df_covid['Date'].dt.month.astype(str)\n",
    "        self.df_county_data['Month'] = self.df_county_data['Date'].dt.month.astype(str)\n",
    "\n",
    "        df_tab = pd.merge(self.df_covid[['Date', 'Population', 'Cases', 'Deaths', 'County', 'State', 'Month', 'fips']], \n",
    "                          self.df_county_data.loc[self.df_county_data['Date'] >= '2020', \n",
    "                                             ['Labor force', 'Unemployment rate', 'fips', 'Month']\n",
    "                                            ],\n",
    "                          how='left', on=['fips', 'Month']\n",
    "                         ).drop('Month', axis=1)\n",
    "    \n",
    "        #self.df_weekly['Date'] = pd.to_datetime(self.df_weekly['Date'])\n",
    "        \n",
    "        df1 = self.county_ratio(df_tab, self.df_weekly.drop('Rate_insured_unemp', axis=1))\n",
    "        df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "        \n",
    "        \n",
    "        #Merge starting with feb to fix Jan outlier\n",
    "        df2 = pd.merge(df1[df1['Date'] > '2020-01-31'], self.df_age, how='left', on='fips')\n",
    "        df2 = pd.merge(df2, self.df_income[['fips', 'Per capita income']], how='left', on='fips')\n",
    "        df2['Date'] = df2['Date'].dt.date.astype(str)\n",
    "        self.df_descartes['Date'] = self.df_descartes['Date'].dt.date.astype(str)\n",
    "        \n",
    "        df3 = pd.merge(df2, self.df_descartes[['Date', 'fips', 'Mobility index', 'State only']], on=['fips', 'Date'], how='left')\n",
    "\n",
    "        df3.append(self.df_descartes[self.df_descartes['State only'] == True].drop(['Samples', 'Raw'], axis=1))\n",
    "        self.df_descartes['Date'] = pd.to_datetime(self.df_descartes['Date'])\n",
    "        \n",
    "        df3.to_csv(path/'combined_data.csv', index=False)\n",
    "        \n",
    "        self.df_merged = df3\n",
    "        \n",
    "        return self.df_merged\n",
    "    \n",
    "    \n",
    "    def us_geo_plot(self, col, time='latest'):\n",
    "        '''\n",
    "        Plots data with Geopandas for continental only display\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            col(str): feature to look at via county level map\n",
    "            \n",
    "            time(str): default='latest', the date to use, if latest retruns\n",
    "                        latest date for which there is data\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            Pass\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "\n",
    "        if time == 'latest':\n",
    "            \n",
    "            # Get last date for which there is data by column given\n",
    "            date = self.df_merged[[col, 'Date']].dropna().tail(1).Date.iloc[0]\n",
    "        \n",
    "        else:\n",
    "            date = time\n",
    "            \n",
    "            \n",
    "        df = self.df_merged.set_index('Date').loc[date, [col, 'fips']]\n",
    "        \n",
    "        df_geo = gpd.GeoDataFrame(self.df_fips, geometry='geometry').merge(df, on='fips')\n",
    " \n",
    "        fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "        ax = df_geo.plot(ax=ax, column=col, legend=True,\n",
    "                        legend_kwds={'label': col,\n",
    "                                     'orientation': 'vertical',\n",
    "                                     'shrink': .2}, \n",
    "                         cmap='OrRd')\n",
    "        plt.xlim(-125, -67)\n",
    "        plt.ylim(24, 50)\n",
    "        title_name = 'US ' + col\n",
    "        \n",
    "        plt.title(title_name)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Pull in the data and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/_DMT/jupyter/covid/get_covid_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /Users/_DMT/jupyter/covid/get_covid_data.py\n",
    "\n",
    "#Combine weekly and monthly unemployment data as granular as possible\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CovidClass.CovidData import CovidData\n",
    "\n",
    "\n",
    "data = CovidData()\n",
    "\n",
    "# Pull COVID Cases/Deaths from USAfacts\n",
    "data.get_covid()\n",
    "\n",
    "# Pull unemployment data from BLS\n",
    "data.get_bls()\n",
    "\n",
    "# Load age demographic data and income\n",
    "data.get_age()\n",
    "data.get_percap_census_data()\n",
    "\n",
    "# Pull latest weekly unemlpoyment claims\n",
    "data.get_weekly()\n",
    "\n",
    "# Get the mobility data from Descartes Labs\n",
    "data.get_descartes()\n",
    "   \n",
    "\n",
    "# Merge the datasets\n",
    "data.merge_data()\n",
    "\n",
    "# Display national cases\n",
    "data.df_covid.pivot_table(index = 'Date', \n",
    "                            values = 'Cases', \n",
    "                            aggfunc='sum')['2020-03-01':].diff().rolling(7).mean().plot()\n",
    "\n",
    "plt.title('Total US cases')\n",
    "plt.show()\n",
    "\n",
    "# Show latest unemployment claims\n",
    "data.df_weekly.pivot_table(index='Date', \n",
    "                           columns='State', \n",
    "                           values='Initial_claims').sum(axis=1).plot()\n",
    "plt.ylabel('Claims in M')\n",
    "plt.title('US total weekly unemployment claims')\n",
    "plt.show()\n",
    "\n",
    "# Plot the mobility data\n",
    "states = ['Colorado', 'California', 'New York', 'Tennessee', 'Texas']\n",
    "\n",
    "pd.pivot_table(data.df_descartes[data.df_descartes['State'].isin(states)],\n",
    "               index='Date', columns=['State'],\n",
    "               values='Mobility index')['2020-03-10':].resample('W').mean().plot()\n",
    "plt.ylabel('Mobility index')\n",
    "plt.title('Movement trends - selected states')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Display national cases\n",
    "data.df_covid.pivot_table(index = 'Date', \n",
    "                            values = 'Cases', \n",
    "                            aggfunc='sum')['2020-03-01':].diff().rolling(7).mean().plot()\n",
    "\n",
    "plt.title('Total US cases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Show latest unemployment claims\n",
    "data.df_weekly.pivot_table(index='Date', \n",
    "                           columns='State', \n",
    "                           values='Initial_claims').sum(axis=1).plot()\n",
    "plt.ylabel('Claims in M')\n",
    "plt.title('US total weekly unemployment claims')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Show latest US unemployment by county\n",
    "data.us_geo_plot('Unemployment rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Show average age\n",
    "data.us_geo_plot('Mean age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "states = ['Colorado', 'California', 'New York', 'Tennessee', 'Texas']\n",
    "\n",
    "pd.pivot_table(data.df_descartes[data.df_descartes['State'].isin(states)],\n",
    "               index='Date', columns=['State'],\n",
    "               values='Mobility index')['2020-03-10':].resample('W').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Saving the timestamps\n",
    "data.dates.to_csv(path/'var_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print('Script complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "standard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
